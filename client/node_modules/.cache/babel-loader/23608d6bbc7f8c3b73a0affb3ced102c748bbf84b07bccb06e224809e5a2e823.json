{"ast":null,"code":"// Using ES6 import syntax\nimport OpenAI from 'openai';\n\n// Initialize the OpenAI configuration with your API key\nconst openai = new OpenAI({\n  apiKey: \"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\",\n  dangerouslyAllowBrowser: true // Use environment variable for security\n});\n\n// Asynchronous function to send a message to OpenAI\nexport async function sendMsgToOpenAi(message) {\n  try {\n    const response = await openai.chat.completions.create({\n      model: \"gpt-4o-mini\",\n      // Use the latest model\n      messages: [{\n        role: \"user\",\n        content: message\n      }],\n      max_tokens: 2000,\n      temperature: 0.7,\n      top_p: 1,\n      frequency_penalty: 0,\n      presence_penalty: 0\n    });\n    return response.data.choices[0].message.content; // Access the content of the response\n  } catch (error) {\n    console.error(\"Error communicating with OpenAI:\", error);\n    throw error; // Rethrow the error for further handling\n  }\n}","map":{"version":3,"names":["OpenAI","openai","apiKey","dangerouslyAllowBrowser","sendMsgToOpenAi","message","response","chat","completions","create","model","messages","role","content","max_tokens","temperature","top_p","frequency_penalty","presence_penalty","data","choices","error","console"],"sources":["C:/Documents/ChatGpt/clone/src/openai.js"],"sourcesContent":["// Using ES6 import syntax\r\nimport OpenAI from 'openai';\r\n\r\n// Initialize the OpenAI configuration with your API key\r\nconst openai = new OpenAI({\r\n    apiKey: \"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\",\r\n    dangerouslyAllowBrowser: true  // Use environment variable for security\r\n });\r\n\r\n\r\n\r\n// Asynchronous function to send a message to OpenAI\r\nexport async function sendMsgToOpenAi(message) {\r\n    try {\r\n        const response = await openai.chat.completions.create({\r\n            model: \"gpt-4o-mini\", // Use the latest model\r\n            messages: [{ role: \"user\", content: message }],\r\n            max_tokens: 2000,\r\n            temperature: 0.7,\r\n            top_p: 1,\r\n            frequency_penalty: 0,\r\n            presence_penalty: 0,\r\n        });\r\n        return response.data.choices[0].message.content; // Access the content of the response\r\n    } catch (error) {\r\n        console.error(\"Error communicating with OpenAI:\", error);\r\n        throw error; // Rethrow the error for further handling\r\n    }\r\n}"],"mappings":"AAAA;AACA,OAAOA,MAAM,MAAM,QAAQ;;AAE3B;AACA,MAAMC,MAAM,GAAG,IAAID,MAAM,CAAC;EACtBE,MAAM,EAAE,sKAAsK;EAC9KC,uBAAuB,EAAE,IAAI,CAAE;AAClC,CAAC,CAAC;;AAIH;AACA,OAAO,eAAeC,eAAeA,CAACC,OAAO,EAAE;EAC3C,IAAI;IACA,MAAMC,QAAQ,GAAG,MAAML,MAAM,CAACM,IAAI,CAACC,WAAW,CAACC,MAAM,CAAC;MAClDC,KAAK,EAAE,aAAa;MAAE;MACtBC,QAAQ,EAAE,CAAC;QAAEC,IAAI,EAAE,MAAM;QAAEC,OAAO,EAAER;MAAQ,CAAC,CAAC;MAC9CS,UAAU,EAAE,IAAI;MAChBC,WAAW,EAAE,GAAG;MAChBC,KAAK,EAAE,CAAC;MACRC,iBAAiB,EAAE,CAAC;MACpBC,gBAAgB,EAAE;IACtB,CAAC,CAAC;IACF,OAAOZ,QAAQ,CAACa,IAAI,CAACC,OAAO,CAAC,CAAC,CAAC,CAACf,OAAO,CAACQ,OAAO,CAAC,CAAC;EACrD,CAAC,CAAC,OAAOQ,KAAK,EAAE;IACZC,OAAO,CAACD,KAAK,CAAC,kCAAkC,EAAEA,KAAK,CAAC;IACxD,MAAMA,KAAK,CAAC,CAAC;EACjB;AACJ","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}